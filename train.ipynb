{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10135,
     "status": "ok",
     "timestamp": 1747027931403,
     "user": {
      "displayName": "ì´ì±„í›ˆ",
      "userId": "14976066403014206527"
     },
     "user_tz": -540
    },
    "id": "MJ_XMFFn8u1N",
    "outputId": "9af97dfa-2b79-4b75-a44f-2837d2121a89"
   },
   "outputs": [],
   "source": [
    "#5/19 í…ŒìŠ¤íŠ¸\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "import os\n",
    "os.chdir('/content/drive/MyDrive/Colab Notebooks/swishnet')\n",
    "import sys\n",
    "sys.path.append(os.getcwd())\n",
    "!pip install import-ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import import_ipynb\n",
    "from dataset import train_data,eval_data\n",
    "from model import swishnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w6P3A6cSF_yC"
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dNj0feKWG7Mr"
   },
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "batch_size = 64\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NkIsds3uRfwG"
   },
   "outputs": [],
   "source": [
    "model = swishnet().to(device)\n",
    "training_data = train_data()\n",
    "evel_data = eval_data()\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(evel_data, batch_size=batch_size, shuffle=True)\n",
    "loss_fn = torch.nn.crossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CYgfiM0iExRL"
   },
   "outputs": [],
   "source": [
    "def one_epoch_loop(train_dataloader, test_dataloader, model, loss_fn, optimizer, device):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "\n",
    "    for batch_idx, (X, y) in enumerate(train_dataloader):\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        preds = pred.argmax(dim=1)\n",
    "        train_correct += (preds == y).sum().item()\n",
    "        train_total += y.size(0)\n",
    "\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f\"[Batch {batch_idx}] Train Loss: {loss.item():.6f}\")\n",
    "\n",
    "    train_acc = train_correct / train_total\n",
    "    train_loss /= train_total #ì—í¬í¬ë‹¹ í‰ê·  loss\n",
    "    \n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in test_dataloader:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            pred = model(X)\n",
    "            loss = loss_fn(pred, y)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            preds = pred.argmax(dim=1)\n",
    "            test_correct += (preds == y).sum().item()\n",
    "            test_total += y.size(0)\n",
    "\n",
    "    test_loss /= test_total\n",
    "    test_acc = test_correct / test_total\n",
    "\n",
    "    return train_loss, test_loss, test_acc, train_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_list = []\n",
    "test_loss_list = []\n",
    "test_acc_list = []\n",
    "train_acc_list = []\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loss, test_loss, test_acc, train_acc = one_epoch_loop(train_dataloader,test_dataloader, model, loss_fn, optimizer)\n",
    "    train_loss_list.append(train_loss)\n",
    "    test_loss_list.append(test_loss)\n",
    "    train_acc_list.append(train_acc)\n",
    "    test_acc_list.append(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "epochs_range = range(1, len(train_loss_list) + 1)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# ğŸ”¹ Loss ê·¸ë˜í”„\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, train_loss_list, label='Train Loss')\n",
    "plt.plot(epochs_range, test_loss_list, label='Test Loss')\n",
    "plt.title('Loss over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# ğŸ”¹ Accuracy ê·¸ë˜í”„\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, train_acc_list, label='Train Accuracy')\n",
    "plt.plot(epochs_range, test_acc_list, label='Test Accuracy')\n",
    "plt.title('Accuracy over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YMrm9LRXSXq3"
   },
   "source": [
    "íŒŒì¼ì„ ì…ë ¥ ë°›ì•„ì„œ í•˜ë‚˜ì˜ ë¦¬ìŠ¤íŠ¸ë¡œ ë‚´ë†“ê²Œ\n",
    "íŒŒì¼ì„ í•˜ë‚˜ ë°›ë‚˜? í•˜ë‚˜ ë°›ì•„ì„œ ì¼ì • êµ¬ê°„ìœ¼ë¡œ ë‚˜ëˆ ì„œ?\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNbg5HnXQsxMl87AnwCLjDb",
   "mount_file_id": "1yxILYlE5WFEPxGmSg01rQIW6eHSi8i5X",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
